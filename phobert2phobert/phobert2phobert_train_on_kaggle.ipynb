{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"9921452219c54cfe8884594dee28dcbe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0e821d07a2ac437abd6c1f9a23aaac02","IPY_MODEL_bbd3df90fb724c4a9205fd74f444185e","IPY_MODEL_75ce409dad004ebeb0e15db1de81eb45"],"layout":"IPY_MODEL_97e924f16ec848afa20d86e5ec65803b"}},"0e821d07a2ac437abd6c1f9a23aaac02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac99e1fd38ae40ff95e8cbb0d4d49de3","placeholder":"â€‹","style":"IPY_MODEL_126f308510884ee39a78454b7d701b24","value":"Map:â€‡100%"}},"bbd3df90fb724c4a9205fd74f444185e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_88114e6d20354968bd6247ddf0c9520e","max":105418,"min":0,"orientation":"horizontal","style":"IPY_MODEL_643d1544fbde44f9b46d3bc1df8e110e","value":105418}},"75ce409dad004ebeb0e15db1de81eb45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e1ccc5ba45442cab8bceefce7975b26","placeholder":"â€‹","style":"IPY_MODEL_f08b769aa55c4085b1969b40e2d7115b","value":"â€‡105418/105418â€‡[04:36&lt;00:00,â€‡554.82â€‡examples/s]"}},"97e924f16ec848afa20d86e5ec65803b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac99e1fd38ae40ff95e8cbb0d4d49de3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"126f308510884ee39a78454b7d701b24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"88114e6d20354968bd6247ddf0c9520e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"643d1544fbde44f9b46d3bc1df8e110e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e1ccc5ba45442cab8bceefce7975b26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f08b769aa55c4085b1969b40e2d7115b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5d3492499094339b8b2f78cc8ba7b9f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3867fe753a494efba1b871722e427df8","IPY_MODEL_3af922b5463443f79d09bdecfe472f18","IPY_MODEL_0232865874f24e9c88f7556c6e10b39d"],"layout":"IPY_MODEL_6b80b4b8e9f94a96b1e73711746b468e"}},"3867fe753a494efba1b871722e427df8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7484b5e7a63145e6823736d226fa881a","placeholder":"â€‹","style":"IPY_MODEL_c19d3220e13f41698a34417f08f8984a","value":"Map:â€‡100%"}},"3af922b5463443f79d09bdecfe472f18":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e4ff1c99ac94aa8b4db7fc07c96561b","max":22642,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ef802c5e87a148ba8b6447e834a19f52","value":22642}},"0232865874f24e9c88f7556c6e10b39d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58076450e26c4852a49d27f79e1d3cf0","placeholder":"â€‹","style":"IPY_MODEL_146aadceba9e4aa19b48b6310415afa0","value":"â€‡22642/22642â€‡[01:01&lt;00:00,â€‡306.85â€‡examples/s]"}},"6b80b4b8e9f94a96b1e73711746b468e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7484b5e7a63145e6823736d226fa881a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c19d3220e13f41698a34417f08f8984a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e4ff1c99ac94aa8b4db7fc07c96561b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef802c5e87a148ba8b6447e834a19f52":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"58076450e26c4852a49d27f79e1d3cf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"146aadceba9e4aa19b48b6310415afa0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4bb588e11ae4c2491411cf5c0b79493":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c84fd6b8ffb04bea8e68fd4868c24926","IPY_MODEL_9e8e1ea4cfba474180876d49015449c3","IPY_MODEL_4bdc3b1da0b247ecaa1d3f439e3bf78a"],"layout":"IPY_MODEL_5a0d19e60bca4cdcbc07acc56723f8a2"}},"c84fd6b8ffb04bea8e68fd4868c24926":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33ccfa885e434698ad4d7d3fc7762ccc","placeholder":"â€‹","style":"IPY_MODEL_5561913d48ba42a68eef8f64c186ea5f","value":"Map:â€‡100%"}},"9e8e1ea4cfba474180876d49015449c3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_408b0cd0425841daad783c10c31bea23","max":22644,"min":0,"orientation":"horizontal","style":"IPY_MODEL_11145b570ff64701b19d658238f8622f","value":22644}},"4bdc3b1da0b247ecaa1d3f439e3bf78a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_729e02d229454cac83599cada3465a95","placeholder":"â€‹","style":"IPY_MODEL_430f121010314c7c960d0b7a8aa0d7d4","value":"â€‡22644/22644â€‡[00:59&lt;00:00,â€‡485.47â€‡examples/s]"}},"5a0d19e60bca4cdcbc07acc56723f8a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33ccfa885e434698ad4d7d3fc7762ccc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5561913d48ba42a68eef8f64c186ea5f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"408b0cd0425841daad783c10c31bea23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11145b570ff64701b19d658238f8622f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"729e02d229454cac83599cada3465a95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"430f121010314c7c960d0b7a8aa0d7d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/ngockhanh5110/nlp-vietnamese-text-summarization/blob/main/notebooks/training_vietnews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"code","source":"OUTPUT_DIR = '/kaggle/working/training/'","metadata":{"id":"Gx4Vg4cbEUJ_","trusted":true,"execution":{"iopub.status.busy":"2024-11-30T20:14:52.258026Z","iopub.execute_input":"2024-11-30T20:14:52.258439Z","iopub.status.idle":"2024-11-30T20:14:52.267160Z","shell.execute_reply.started":"2024-11-30T20:14:52.258402Z","shell.execute_reply":"2024-11-30T20:14:52.266350Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"%%capture\n!pip install transformers\n!pip install datasets\n!pip install gdown\n!pip install rouge_score\n!pip install evaluate","metadata":{"id":"YzywNFmeKVgx","trusted":true,"execution":{"iopub.status.busy":"2024-11-30T20:14:52.268856Z","iopub.execute_input":"2024-11-30T20:14:52.269212Z","iopub.status.idle":"2024-11-30T20:15:36.374954Z","shell.execute_reply.started":"2024-11-30T20:14:52.269173Z","shell.execute_reply":"2024-11-30T20:15:36.373919Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import glob\nimport pandas as pd\nimport concurrent.futures\nfrom datasets import *\nimport gdown\nimport datasets\nimport evaluate\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer,EncoderDecoderModel\nimport transformers\nimport os\nos.environ['WANDB_DISABLED'] = 'true'","metadata":{"id":"TZYjioRkKviO","trusted":true,"execution":{"iopub.status.busy":"2024-11-30T20:15:36.376242Z","iopub.execute_input":"2024-11-30T20:15:36.376534Z","iopub.status.idle":"2024-11-30T20:15:55.188740Z","shell.execute_reply.started":"2024-11-30T20:15:36.376506Z","shell.execute_reply":"2024-11-30T20:15:55.187953Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Processing data","metadata":{"id":"4IteMtlc58-y"}},{"cell_type":"code","source":"gdown.download('https://drive.google.com/file/d/13FF_pNJth3GeKHQEzmD-voywcTmjAFIb/view?usp=sharing','/kaggle/working/train_data.csv',fuzzy=True)\ngdown.download('https://drive.google.com/file/d/1a3xuGQA1Ztpti8kzfBtO4e0zSFbUFECq/view?usp=sharing','/kaggle/working/val_data.csv',fuzzy=True)\ngdown.download('https://drive.google.com/file/d/1S-POATiC3cbMEUuEmkYOf_NE55e2MErU/view?usp=sharing','/kaggle/working/test_data.csv',fuzzy=True)","metadata":{"id":"m5bvqztSbXkr","outputId":"90036a0e-177f-4f84-db73-70a798732beb","trusted":true,"execution":{"iopub.status.busy":"2024-11-30T20:15:55.190537Z","iopub.execute_input":"2024-11-30T20:15:55.191094Z","iopub.status.idle":"2024-11-30T20:16:11.140424Z","shell.execute_reply.started":"2024-11-30T20:15:55.191065Z","shell.execute_reply":"2024-11-30T20:16:11.139622Z"}},"outputs":[{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=13FF_pNJth3GeKHQEzmD-voywcTmjAFIb\nFrom (redirected): https://drive.google.com/uc?id=13FF_pNJth3GeKHQEzmD-voywcTmjAFIb&confirm=t&uuid=bccba3f6-5e6a-49fc-8121-756cebbb7679\nTo: /kaggle/working/train_data.csv\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 218M/218M [00:01<00:00, 207MB/s] \nDownloading...\nFrom: https://drive.google.com/uc?id=1a3xuGQA1Ztpti8kzfBtO4e0zSFbUFECq\nTo: /kaggle/working/val_data.csv\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46.7M/46.7M [00:00<00:00, 229MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1S-POATiC3cbMEUuEmkYOf_NE55e2MErU\nTo: /kaggle/working/test_data.csv\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46.9M/46.9M [00:00<00:00, 222MB/s]\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/test_data.csv'"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/working/train_data.csv')\nval_df = pd.read_csv('/kaggle/working/val_data.csv')\ntest_df = pd.read_csv('/kaggle/working/test_data.csv')","metadata":{"id":"d4c0pl5BAl3f","trusted":true,"execution":{"iopub.status.busy":"2024-11-30T20:16:11.141671Z","iopub.execute_input":"2024-11-30T20:16:11.142295Z","iopub.status.idle":"2024-11-30T20:16:17.553135Z","shell.execute_reply.started":"2024-11-30T20:16:11.142247Z","shell.execute_reply":"2024-11-30T20:16:17.552421Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### **Data Preprocessing**","metadata":{"id":"3FO5ESocXvlK"}},{"cell_type":"code","source":"tokenizer =  AutoTokenizer.from_pretrained(\"vinai/phobert-base\")","metadata":{"id":"sgTiC0rhMb7C","outputId":"f461337b-23a6-4f5d-cd03-fdef7165219e","trusted":true,"execution":{"iopub.status.busy":"2024-11-30T20:16:17.554160Z","iopub.execute_input":"2024-11-30T20:16:17.554427Z","iopub.status.idle":"2024-11-30T20:16:19.202671Z","shell.execute_reply.started":"2024-11-30T20:16:17.554401Z","shell.execute_reply":"2024-11-30T20:16:19.201777Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/557 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81387817492e4be7a6ff89e8b927ad72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fec7404d8d24d9680ea261f4c2cd962"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"957a2093f5434e83b32d92297b631ce1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/3.13M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"800100b0c49e4c7db69267f7e7fbbcb0"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# set encoder decoder tying to True\nroberta_shared = EncoderDecoderModel.from_encoder_decoder_pretrained(\"vinai/phobert-base\", \"vinai/phobert-base\", tie_encoder_decoder=False)","metadata":{"id":"dlvUpJZFBBCY","outputId":"13ca47bf-523a-49ba-e5f3-fc8b265494cf","trusted":true,"execution":{"iopub.status.busy":"2024-11-30T20:16:19.203840Z","iopub.execute_input":"2024-11-30T20:16:19.204116Z","iopub.status.idle":"2024-11-30T20:16:23.969038Z","shell.execute_reply.started":"2024-11-30T20:16:19.204091Z","shell.execute_reply":"2024-11-30T20:16:23.968031Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/543M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"892388775e434929a91b853b03d2ea93"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForCausalLM were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.1.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.10.crossattention.output.dense.bias', 'roberta.encoder.layer.10.crossattention.output.dense.weight', 'roberta.encoder.layer.10.crossattention.self.key.bias', 'roberta.encoder.layer.10.crossattention.self.key.weight', 'roberta.encoder.layer.10.crossattention.self.query.bias', 'roberta.encoder.layer.10.crossattention.self.query.weight', 'roberta.encoder.layer.10.crossattention.self.value.bias', 'roberta.encoder.layer.10.crossattention.self.value.weight', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.11.crossattention.output.dense.bias', 'roberta.encoder.layer.11.crossattention.output.dense.weight', 'roberta.encoder.layer.11.crossattention.self.key.bias', 'roberta.encoder.layer.11.crossattention.self.key.weight', 'roberta.encoder.layer.11.crossattention.self.query.bias', 'roberta.encoder.layer.11.crossattention.self.query.weight', 'roberta.encoder.layer.11.crossattention.self.value.bias', 'roberta.encoder.layer.11.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.6.crossattention.output.dense.bias', 'roberta.encoder.layer.6.crossattention.output.dense.weight', 'roberta.encoder.layer.6.crossattention.self.key.bias', 'roberta.encoder.layer.6.crossattention.self.key.weight', 'roberta.encoder.layer.6.crossattention.self.query.bias', 'roberta.encoder.layer.6.crossattention.self.query.weight', 'roberta.encoder.layer.6.crossattention.self.value.bias', 'roberta.encoder.layer.6.crossattention.self.value.weight', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.7.crossattention.output.dense.bias', 'roberta.encoder.layer.7.crossattention.output.dense.weight', 'roberta.encoder.layer.7.crossattention.self.key.bias', 'roberta.encoder.layer.7.crossattention.self.key.weight', 'roberta.encoder.layer.7.crossattention.self.query.bias', 'roberta.encoder.layer.7.crossattention.self.query.weight', 'roberta.encoder.layer.7.crossattention.self.value.bias', 'roberta.encoder.layer.7.crossattention.self.value.weight', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.8.crossattention.output.dense.bias', 'roberta.encoder.layer.8.crossattention.output.dense.weight', 'roberta.encoder.layer.8.crossattention.self.key.bias', 'roberta.encoder.layer.8.crossattention.self.key.weight', 'roberta.encoder.layer.8.crossattention.self.query.bias', 'roberta.encoder.layer.8.crossattention.self.query.weight', 'roberta.encoder.layer.8.crossattention.self.value.bias', 'roberta.encoder.layer.8.crossattention.self.value.weight', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.9.crossattention.output.dense.bias', 'roberta.encoder.layer.9.crossattention.output.dense.weight', 'roberta.encoder.layer.9.crossattention.self.key.bias', 'roberta.encoder.layer.9.crossattention.self.key.weight', 'roberta.encoder.layer.9.crossattention.self.query.bias', 'roberta.encoder.layer.9.crossattention.self.query.weight', 'roberta.encoder.layer.9.crossattention.self.value.bias', 'roberta.encoder.layer.9.crossattention.self.value.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nEncoderDecoderModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"train_data =  Dataset.from_pandas(train_df)\nval_data =  Dataset.from_pandas(val_df)\ntest_data =  Dataset.from_pandas(test_df)","metadata":{"id":"U08MrUK9LcUM","trusted":true,"execution":{"iopub.status.busy":"2024-11-30T20:16:23.970367Z","iopub.execute_input":"2024-11-30T20:16:23.970793Z","iopub.status.idle":"2024-11-30T20:16:27.840243Z","shell.execute_reply.started":"2024-11-30T20:16:23.970747Z","shell.execute_reply":"2024-11-30T20:16:27.839531Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train_set = train_data.map(lambda  x:\n                           {'input_ids': tokenizer(x['original'], padding=\"max_length\", truncation=True, max_length=256).input_ids,\n                               'labels': tokenizer(x['summary'], padding=\"max_length\", truncation=True, max_length=32).input_ids,\n                           })\nval_set = val_data.map(lambda  x:\n                            {'input_ids': tokenizer(x['original'], padding=\"max_length\", truncation=True, max_length=256).input_ids,\n                               'labels': tokenizer(x['summary'], padding=\"max_length\", truncation=True, max_length=32).input_ids,\n                           })\ntest_set = test_data.map(lambda  x:\n                            {'input_ids': tokenizer(x['original'], padding=\"max_length\", truncation=True, max_length=256).input_ids,\n                               'labels': tokenizer(x['summary'], padding=\"max_length\", truncation=True, max_length=32).input_ids,\n                           })","metadata":{"id":"nap6X4BOXVhu","outputId":"f1b0bb06-8028-4c96-fbb3-ee2fa5025154","trusted":true,"execution":{"iopub.status.busy":"2024-11-30T20:16:27.841318Z","iopub.execute_input":"2024-11-30T20:16:27.841583Z","iopub.status.idle":"2024-11-30T20:21:23.170990Z","shell.execute_reply.started":"2024-11-30T20:16:27.841557Z","shell.execute_reply":"2024-11-30T20:21:23.169978Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/105418 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3eb7abf443c2441caff358ac08ff941e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/22642 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff9c43834dc448abb56488697b7d8c03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/22644 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42650c972bcb44c19c54605d025437ee"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"roberta_shared.config","metadata":{"id":"dRHydsOcZRIz","outputId":"51a4291a-a110-48d1-c024-65e5590106f2","trusted":true,"execution":{"iopub.status.busy":"2024-11-30T20:21:23.173969Z","iopub.execute_input":"2024-11-30T20:21:23.174291Z","iopub.status.idle":"2024-11-30T20:21:23.182231Z","shell.execute_reply.started":"2024-11-30T20:21:23.174259Z","shell.execute_reply":"2024-11-30T20:21:23.181205Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"EncoderDecoderConfig {\n  \"decoder\": {\n    \"_name_or_path\": \"vinai/phobert-base\",\n    \"add_cross_attention\": true,\n    \"architectures\": [\n      \"RobertaForMaskedLM\"\n    ],\n    \"attention_probs_dropout_prob\": 0.1,\n    \"bad_words_ids\": null,\n    \"begin_suppress_tokens\": null,\n    \"bos_token_id\": 0,\n    \"chunk_size_feed_forward\": 0,\n    \"classifier_dropout\": null,\n    \"cross_attention_hidden_size\": null,\n    \"decoder_start_token_id\": null,\n    \"diversity_penalty\": 0.0,\n    \"do_sample\": false,\n    \"early_stopping\": false,\n    \"encoder_no_repeat_ngram_size\": 0,\n    \"eos_token_id\": 2,\n    \"exponential_decay_length_penalty\": null,\n    \"finetuning_task\": null,\n    \"forced_bos_token_id\": null,\n    \"forced_eos_token_id\": null,\n    \"gradient_checkpointing\": false,\n    \"hidden_act\": \"gelu\",\n    \"hidden_dropout_prob\": 0.1,\n    \"hidden_size\": 768,\n    \"id2label\": {\n      \"0\": \"LABEL_0\",\n      \"1\": \"LABEL_1\"\n    },\n    \"initializer_range\": 0.02,\n    \"intermediate_size\": 3072,\n    \"is_decoder\": true,\n    \"is_encoder_decoder\": false,\n    \"label2id\": {\n      \"LABEL_0\": 0,\n      \"LABEL_1\": 1\n    },\n    \"layer_norm_eps\": 1e-05,\n    \"length_penalty\": 1.0,\n    \"max_length\": 20,\n    \"max_position_embeddings\": 258,\n    \"min_length\": 0,\n    \"model_type\": \"roberta\",\n    \"no_repeat_ngram_size\": 0,\n    \"num_attention_heads\": 12,\n    \"num_beam_groups\": 1,\n    \"num_beams\": 1,\n    \"num_hidden_layers\": 12,\n    \"num_return_sequences\": 1,\n    \"output_attentions\": false,\n    \"output_hidden_states\": false,\n    \"output_scores\": false,\n    \"pad_token_id\": 1,\n    \"position_embedding_type\": \"absolute\",\n    \"prefix\": null,\n    \"problem_type\": null,\n    \"pruned_heads\": {},\n    \"remove_invalid_values\": false,\n    \"repetition_penalty\": 1.0,\n    \"return_dict\": true,\n    \"return_dict_in_generate\": false,\n    \"sep_token_id\": null,\n    \"suppress_tokens\": null,\n    \"task_specific_params\": null,\n    \"temperature\": 1.0,\n    \"tf_legacy_loss\": false,\n    \"tie_encoder_decoder\": false,\n    \"tie_word_embeddings\": true,\n    \"tokenizer_class\": \"PhobertTokenizer\",\n    \"top_k\": 50,\n    \"top_p\": 1.0,\n    \"torch_dtype\": null,\n    \"torchscript\": false,\n    \"type_vocab_size\": 1,\n    \"typical_p\": 1.0,\n    \"use_bfloat16\": false,\n    \"use_cache\": true,\n    \"vocab_size\": 64001\n  },\n  \"encoder\": {\n    \"_name_or_path\": \"vinai/phobert-base\",\n    \"add_cross_attention\": false,\n    \"architectures\": [\n      \"RobertaForMaskedLM\"\n    ],\n    \"attention_probs_dropout_prob\": 0.1,\n    \"bad_words_ids\": null,\n    \"begin_suppress_tokens\": null,\n    \"bos_token_id\": 0,\n    \"chunk_size_feed_forward\": 0,\n    \"classifier_dropout\": null,\n    \"cross_attention_hidden_size\": null,\n    \"decoder_start_token_id\": null,\n    \"diversity_penalty\": 0.0,\n    \"do_sample\": false,\n    \"early_stopping\": false,\n    \"encoder_no_repeat_ngram_size\": 0,\n    \"eos_token_id\": 2,\n    \"exponential_decay_length_penalty\": null,\n    \"finetuning_task\": null,\n    \"forced_bos_token_id\": null,\n    \"forced_eos_token_id\": null,\n    \"gradient_checkpointing\": false,\n    \"hidden_act\": \"gelu\",\n    \"hidden_dropout_prob\": 0.1,\n    \"hidden_size\": 768,\n    \"id2label\": {\n      \"0\": \"LABEL_0\",\n      \"1\": \"LABEL_1\"\n    },\n    \"initializer_range\": 0.02,\n    \"intermediate_size\": 3072,\n    \"is_decoder\": false,\n    \"is_encoder_decoder\": false,\n    \"label2id\": {\n      \"LABEL_0\": 0,\n      \"LABEL_1\": 1\n    },\n    \"layer_norm_eps\": 1e-05,\n    \"length_penalty\": 1.0,\n    \"max_length\": 20,\n    \"max_position_embeddings\": 258,\n    \"min_length\": 0,\n    \"model_type\": \"roberta\",\n    \"no_repeat_ngram_size\": 0,\n    \"num_attention_heads\": 12,\n    \"num_beam_groups\": 1,\n    \"num_beams\": 1,\n    \"num_hidden_layers\": 12,\n    \"num_return_sequences\": 1,\n    \"output_attentions\": false,\n    \"output_hidden_states\": false,\n    \"output_scores\": false,\n    \"pad_token_id\": 1,\n    \"position_embedding_type\": \"absolute\",\n    \"prefix\": null,\n    \"problem_type\": null,\n    \"pruned_heads\": {},\n    \"remove_invalid_values\": false,\n    \"repetition_penalty\": 1.0,\n    \"return_dict\": true,\n    \"return_dict_in_generate\": false,\n    \"sep_token_id\": null,\n    \"suppress_tokens\": null,\n    \"task_specific_params\": null,\n    \"temperature\": 1.0,\n    \"tf_legacy_loss\": false,\n    \"tie_encoder_decoder\": false,\n    \"tie_word_embeddings\": true,\n    \"tokenizer_class\": \"PhobertTokenizer\",\n    \"top_k\": 50,\n    \"top_p\": 1.0,\n    \"torch_dtype\": null,\n    \"torchscript\": false,\n    \"type_vocab_size\": 1,\n    \"typical_p\": 1.0,\n    \"use_bfloat16\": false,\n    \"use_cache\": true,\n    \"vocab_size\": 64001\n  },\n  \"is_encoder_decoder\": true,\n  \"model_type\": \"encoder-decoder\",\n  \"transformers_version\": \"4.45.1\"\n}"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"### **Warm-starting the Encoder-Decoder Model**","metadata":{"id":"aEjb026cNC38"}},{"cell_type":"code","source":"# set special tokens\nroberta_shared.config.decoder_start_token_id = tokenizer.bos_token_id\nroberta_shared.config.eos_token_id = tokenizer.eos_token_id\nroberta_shared.config.pad_token_id = tokenizer.pad_token_id\n# sensible parameters for beam search\n# set decoding params\nroberta_shared.config.max_length = 32\nroberta_shared.config.early_stopping = True\nroberta_shared.config.no_repeat_ngram_size = 3\nroberta_shared.config.length_penalty = 2.0\nroberta_shared.config.num_beams = 4\nroberta_shared.config.vocab_size = roberta_shared.config.encoder.vocab_size","metadata":{"id":"JD2jv3GkyjR-","trusted":true,"execution":{"iopub.status.busy":"2024-11-30T20:21:23.183325Z","iopub.execute_input":"2024-11-30T20:21:23.183595Z","iopub.status.idle":"2024-11-30T20:21:23.195014Z","shell.execute_reply.started":"2024-11-30T20:21:23.183568Z","shell.execute_reply":"2024-11-30T20:21:23.194263Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# load rouge for validation\nrouge = evaluate.load('rouge')\n\ndef compute_metrics(pred):\n    labels_ids = pred.label_ids\n    pred_ids = pred.predictions\n    \n    # all unnecessary tokens are removed\n    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n\n    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n\n    return {\n        \"rouge2_precision\": round(rouge_output.precision, 4),\n        \"rouge2_recall\": round(rouge_output.recall, 4),\n        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T20:22:03.869333Z","iopub.execute_input":"2024-11-30T20:22:03.869983Z","iopub.status.idle":"2024-11-30T20:22:04.948469Z","shell.execute_reply.started":"2024-11-30T20:22:03.869948Z","shell.execute_reply":"2024-11-30T20:22:04.947793Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f6308b98e2e4d8cba02b7ec7f633359"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# set training arguments - these params are not really tuned, feel free to change\nbatch_size = 32\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir= OUTPUT_DIR,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    predict_with_generate=True,\n    # evaluate_during_training=True,\n    do_train=True,\n    do_eval=True,\n    logging_steps=200,  # set to 2000 for full training\n    save_steps=10000,  # set to 500 for full training\n    eval_steps=10000,  # set to 7500 for full training\n    warmup_steps=3000,  # set to 3000 for full training\n    num_train_epochs=10, #uncomment for full training\n    overwrite_output_dir=True,\n    save_total_limit=50,\n    fp16=True,\n)\n\n# instantiate trainer\ntrainer = Seq2SeqTrainer(\n    model=roberta_shared,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=train_set,\n    eval_dataset=val_set,\n    tokenizer = tokenizer\n)\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T20:22:05.653141Z","iopub.execute_input":"2024-11-30T20:22:05.653495Z"}},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n/opt/conda/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n/opt/conda/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='166' max='32950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  166/32950 02:51 < 9:29:59, 0.96 it/s, Epoch 0.05/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null}]}